{
	"version": "https://jsonfeed.org/version/1",
	"title": "Becky Sweger",
	"icon": "https://micro.blog/bsweger/avatar.jpg",
	"home_page_url": "https://beckysweger.com/",
	"feed_url": "https://beckysweger.com/feed.json",
	"items": [
		
			{
				"id": "http://bsweger.micro.blog/2025/02/11/i-heard-you-like-usaspending.html",
				"title": "I heard you like usaspending data, so have a PostgreSQL",
				"content_html": "<p>Working in the open has many upsides, one of which is the ability to share stories about a project without revealing anything proprietary.</p>\n<p>So this is a story about the software project that culminated in the 2017 relaunch of <a href=\"https://www.usaspending.gov/\">usaspending.gov</a>.  Not only was the code open source (<a href=\"https://github.com/fedspendingtransparency\">it still is</a>), but our JIRA tickets were open to all, and we had a website for collaborating with the public and other feds to develop the data standards that power the site.</p>\n<p>My time as the technical lead on that project is a career highlight, and it&rsquo;s been on my mind as usaspending.gov and all federal data are getting attention. Feeling an urge to archive, I recently checked to see if the usaspending backend database is still available to the public. <a href=\"https://onevoicecrm.my.site.com/usaspending/s/database-download\">It is</a>!</p>\n<p>Having that PostgreSQL archive is important right now, but the original reason for making it available was a creative workaround to a software delivery conundrum</p>\n<p>The law behind an expanded and improved usaspending.gov (the <a href=\"https://www.congress.gov/bill/113th-congress/senate-bill/994\">DATA Act</a>) mandated an implementation no later than May 2017. The team was maybe a sprint away from this deadline when we found a data aggregation bug that caused some incorrect totals on the test website. It was a relatively straightforward problem and absolutely fixable in the remaining time before launch.</p>\n<p>However, making that fix would mean no time to implement the last remaining &ldquo;must have&rdquo; feature before going live: a way to download the site&rsquo;s data. Providing the ability to download search results was not only a critical capability⎻it was something promised on the project&rsquo;s road map.</p>\n<p>And deviating from that roadmap would have been a sign of failure to the many people who believed that a government-wide, agile, open data software development project could not succeed.</p>\n<p>So we faced that classic software delivery quandry: can&rsquo;t move the date, can&rsquo;t change the scope.</p>\n<p>We obviously prioritized fixing the data bug. As for providing a data download feature, someone on the team had the idea to contact AWS, who made a <a href=\"https://aws.amazon.com/blogs/publicsector/announcing-usaspending-gov-on-an-amazon-rds-snapshot/\">snapshot of our PostgreSQL database available as part of their open data program</a> in time for launch.¹</p>\n<p>Not a user-friendly download capability², but a download capability nonetheless. And that&rsquo;s the original reason for publishing a database snapshot for usaspending.gov.</p>\n<p>¹ It&rsquo;s not on AWS anymore, but the announcement page lives on!\n² A more traditional data download feature quickly followed the website&rsquo;s launch.</p>\n",
				"content_text": "Working in the open has many upsides, one of which is the ability to share stories about a project without revealing anything proprietary. \r\n\r\nSo this is a story about the software project that culminated in the 2017 relaunch of [usaspending.gov](https://www.usaspending.gov/).  Not only was the code open source ([it still is](https://github.com/fedspendingtransparency)), but our JIRA tickets were open to all, and we had a website for collaborating with the public and other feds to develop the data standards that power the site.\r\n\r\nMy time as the technical lead on that project is a career highlight, and it's been on my mind as usaspending.gov and all federal data are getting attention. Feeling an urge to archive, I recently checked to see if the usaspending backend database is still available to the public. [It is](https://onevoicecrm.my.site.com/usaspending/s/database-download)!\r\n\r\nHaving that PostgreSQL archive is important right now, but the original reason for making it available was a creative workaround to a software delivery conundrum\r\n\r\nThe law behind an expanded and improved usaspending.gov (the [DATA Act](https://www.congress.gov/bill/113th-congress/senate-bill/994)) mandated an implementation no later than May 2017. The team was maybe a sprint away from this deadline when we found a data aggregation bug that caused some incorrect totals on the test website. It was a relatively straightforward problem and absolutely fixable in the remaining time before launch.\r\n\r\nHowever, making that fix would mean no time to implement the last remaining \"must have\" feature before going live: a way to download the site's data. Providing the ability to download search results was not only a critical capability⎻it was something promised on the project's road map.\r\n\r\nAnd deviating from that roadmap would have been a sign of failure to the many people who believed that a government-wide, agile, open data software development project could not succeed.\r\n\r\nSo we faced that classic software delivery quandry: can't move the date, can't change the scope.\r\n\r\nWe obviously prioritized fixing the data bug. As for providing a data download feature, someone on the team had the idea to contact AWS, who made a [snapshot of our PostgreSQL database available as part of their open data program](https://aws.amazon.com/blogs/publicsector/announcing-usaspending-gov-on-an-amazon-rds-snapshot/) in time for launch.¹\r\n\r\nNot a user-friendly download capability², but a download capability nonetheless. And that's the original reason for publishing a database snapshot for usaspending.gov.\r\n\r\n¹ It's not on AWS anymore, but the announcement page lives on!\r\n² A more traditional data download feature quickly followed the website's launch.\r\n\r\n",
				"date_published": "2025-02-11T00:21:51-05:00",
				"url": "https://beckysweger.com/2025/02/11/i-heard-you-like-usaspending.html",
				"tags": ["stories"]
			},
			{
				"id": "http://bsweger.micro.blog/2025/02/04/using-polars-for-anonymous-access.html",
				"title": "Using Polars for anonymous access to public data on S3",
				"content_html": "<p><a href=\"https://docs.pola.rs/\">Polars</a> is a really handy go-to for working with public data hosted on AWS S3, and I prefer it over Pandas for most work these days. Using Polars to get a <a href=\"https://docs.pola.rs/api/python/stable/reference/dataframe/index.html\">DataFrame</a> via a bucket&rsquo;s HTTPS endpoint is straightforward:</p>\n<pre tabindex=\"0\"><code>df = pl.read_parquet(\n  &quot;https://ookla-open-data.s3.us-west-2.amazonaws.com/parquet/performance/type=fixed/year=2024/quarter=4/2024-10-01_performance_fixed_tiles.parquet&quot;\n)\n\ndf.select([&quot;quadkey&quot;, &quot;avg_d_kbps&quot;, &quot;avg_u_kbps&quot;, &quot;tests&quot;]).head()\n┌──────────────────┬────────────┬────────────┬───────┐\n│ quadkey          ┆ avg_d_kbps ┆ avg_u_kbps ┆ tests │\n│ ---              ┆ ---        ┆ ---        ┆ ---   │\n│ str              ┆ i64        ┆ i64        ┆ i64   │\n╞══════════════════╪════════════╪════════════╪═══════╡\n│ 0022133222312323 ┆ 33682      ┆ 3278       ┆ 1     │\n│ 0022133222330031 ┆ 97271      ┆ 14686      ┆ 2     │\n│ 0022133222330033 ┆ 92047      ┆ 27325      ┆ 1     │\n│ 0022232311221201 ┆ 537        ┆ 255        ┆ 1     │\n│ 0022302331120033 ┆ 104525     ┆ 4896       ┆ 1     │\n└──────────────────┴────────────┴────────────┴───────┘\n</code></pre><p>However, to read hive-partitioned S3 data or to specify a glob pattern, you&rsquo;ll need to use the <code>s3://</code> protocol. Polars supports this, but the documentation doesn&rsquo;t provide a clear example for bypassing a credentials check and accessing public data anonymously.</p>\n<p>Using the same dataset as above, here&rsquo;s the <code>storage_options</code> incantation that&rsquo;s akin to the AWS CLI&rsquo;s <code>--no-sign-request</code> option. In this example, 2024 is further partitioned into quarters; Polars detects the partitions and slurps multiple files into a single dataframe.</p>\n<pre tabindex=\"0\"><code>df1 = pl.read_parquet(\n  &quot;s3://ookla-open-data/parquet/performance/type=fixed/year=2024/&quot;,\n  storage_options={&quot;skip_signature&quot;: &quot;true&quot;}\n)\n\ndf1.select([&quot;quarter&quot;, &quot;quadkey&quot;, &quot;avg_d_kbps&quot;, &quot;avg_u_kbps&quot;, &quot;tests&quot;]).head()\n┌─────────┬──────────────────┬────────────┬────────────┬───────┐\n│ quarter ┆ quadkey          ┆ avg_d_kbps ┆ avg_u_kbps ┆ tests │\n│ ---     ┆ ---              ┆ ---        ┆ ---        ┆ ---   │\n│ i64     ┆ str              ┆ i64        ┆ i64        ┆ i64   │\n╞═════════╪══════════════════╪════════════╪════════════╪═══════╡\n│ 1       ┆ 0022133222312323 ┆ 64266      ┆ 7578       ┆ 2     │\n│ 1       ┆ 0022133222330012 ┆ 158062     ┆ 14698      ┆ 1     │\n│ 1       ┆ 0022133222330030 ┆ 126380     ┆ 5043       ┆ 3     │\n│ 1       ┆ 0022133222330031 ┆ 87525      ┆ 10572      ┆ 3     │\n│ 1       ┆ 0022133222330032 ┆ 58296      ┆ 8058       ┆ 13    │\n└─────────┴──────────────────┴────────────┴────────────┴───────┘\n</code></pre>",
				"content_text": "[Polars](https://docs.pola.rs/) is a really handy go-to for working with public data hosted on AWS S3, and I prefer it over Pandas for most work these days. Using Polars to get a [DataFrame](https://docs.pola.rs/api/python/stable/reference/dataframe/index.html) via a bucket's HTTPS endpoint is straightforward:\n\n```\ndf = pl.read_parquet(\n  \"https://ookla-open-data.s3.us-west-2.amazonaws.com/parquet/performance/type=fixed/year=2024/quarter=4/2024-10-01_performance_fixed_tiles.parquet\"\n)\n\ndf.select([\"quadkey\", \"avg_d_kbps\", \"avg_u_kbps\", \"tests\"]).head()\n┌──────────────────┬────────────┬────────────┬───────┐\n│ quadkey          ┆ avg_d_kbps ┆ avg_u_kbps ┆ tests │\n│ ---              ┆ ---        ┆ ---        ┆ ---   │\n│ str              ┆ i64        ┆ i64        ┆ i64   │\n╞══════════════════╪════════════╪════════════╪═══════╡\n│ 0022133222312323 ┆ 33682      ┆ 3278       ┆ 1     │\n│ 0022133222330031 ┆ 97271      ┆ 14686      ┆ 2     │\n│ 0022133222330033 ┆ 92047      ┆ 27325      ┆ 1     │\n│ 0022232311221201 ┆ 537        ┆ 255        ┆ 1     │\n│ 0022302331120033 ┆ 104525     ┆ 4896       ┆ 1     │\n└──────────────────┴────────────┴────────────┴───────┘\n```\nHowever, to read hive-partitioned S3 data or to specify a glob pattern, you'll need to use the `s3://` protocol. Polars supports this, but the documentation doesn't provide a clear example for bypassing a credentials check and accessing public data anonymously.\n\nUsing the same dataset as above, here's the `storage_options` incantation that's akin to the AWS CLI's `--no-sign-request` option. In this example, 2024 is further partitioned into quarters; Polars detects the partitions and slurps multiple files into a single dataframe.\n\n```\ndf1 = pl.read_parquet(\n  \"s3://ookla-open-data/parquet/performance/type=fixed/year=2024/\",\n  storage_options={\"skip_signature\": \"true\"}\n)\n\ndf1.select([\"quarter\", \"quadkey\", \"avg_d_kbps\", \"avg_u_kbps\", \"tests\"]).head()\n┌─────────┬──────────────────┬────────────┬────────────┬───────┐\n│ quarter ┆ quadkey          ┆ avg_d_kbps ┆ avg_u_kbps ┆ tests │\n│ ---     ┆ ---              ┆ ---        ┆ ---        ┆ ---   │\n│ i64     ┆ str              ┆ i64        ┆ i64        ┆ i64   │\n╞═════════╪══════════════════╪════════════╪════════════╪═══════╡\n│ 1       ┆ 0022133222312323 ┆ 64266      ┆ 7578       ┆ 2     │\n│ 1       ┆ 0022133222330012 ┆ 158062     ┆ 14698      ┆ 1     │\n│ 1       ┆ 0022133222330030 ┆ 126380     ┆ 5043       ┆ 3     │\n│ 1       ┆ 0022133222330031 ┆ 87525      ┆ 10572      ┆ 3     │\n│ 1       ┆ 0022133222330032 ┆ 58296      ┆ 8058       ┆ 13    │\n└─────────┴──────────────────┴────────────┴────────────┴───────┘\n```\n",
				"date_published": "2025-02-04T20:45:57-05:00",
				"url": "https://beckysweger.com/2025/02/04/using-polars-for-anonymous-access.html",
				"tags": ["til","python","polars"]
			},
			{
				"id": "http://bsweger.micro.blog/2025/01/27/a-few-small-repairs.html",
				"title": "A few small repairs",
				"content_html": "<p>Some more micro-improvements in service to the <a href=\"https://beckysweger.com/2024/03/23/the-technical-debt-of-a.html\">technical debt of a thousand paper cuts</a>:</p>\n<ul>\n<li><a href=\"https://osxdaily.com/2016/09/09/view-folder-tree-terminal-mac-os-tree-equivalent/\">Installed tree on MacOS</a>.</li>\n<li>Switched terminals again, this time to <a href=\"https://ghostty.org/\">Ghostty</a>. Warp was good (especially the <a href=\"https://docs.warp.dev/features/blocks\">blocks</a>), but the ever-increasing AI focus got tedious.</li>\n<li>Installed a VSCode extension that <a href=\"https://marketplace.visualstudio.com/items?itemName=yzhang.markdown-all-in-one\">renders GitHub-flavored markdown correctly</a>. No more mediocre markdown previews.</li>\n<li>Replaced the nano editor with <a href=\"https://micro-editor.github.io/\">micro</a> because I want terminal stuff to be colorful by default.</li>\n<li>Began dropping <a href=\"https://setuptools-scm.readthedocs.io/en/stable/\">setuptools-scm</a> into Python packages to handle dynamic versioning.</li>\n<li>Started using sparse git checkouts for working on subsets of big old repos.</li>\n</ul>\n",
				"content_text": "Some more micro-improvements in service to the [technical debt of a thousand paper cuts](https://beckysweger.com/2024/03/23/the-technical-debt-of-a.html):\n\n- [Installed tree on MacOS](https://osxdaily.com/2016/09/09/view-folder-tree-terminal-mac-os-tree-equivalent/).\n- Switched terminals again, this time to [Ghostty](https://ghostty.org/). Warp was good (especially the [blocks](https://docs.warp.dev/features/blocks)), but the ever-increasing AI focus got tedious.\n- Installed a VSCode extension that [renders GitHub-flavored markdown correctly](https://marketplace.visualstudio.com/items?itemName=yzhang.markdown-all-in-one). No more mediocre markdown previews.\n- Replaced the nano editor with [micro](https://micro-editor.github.io/) because I want terminal stuff to be colorful by default.\n- Began dropping [setuptools-scm](https://setuptools-scm.readthedocs.io/en/stable/) into Python packages to handle dynamic versioning.\n- Started using sparse git checkouts for working on subsets of big old repos.\n",
				"date_published": "2025-01-27T22:48:47-05:00",
				"url": "https://beckysweger.com/2025/01/27/a-few-small-repairs.html",
				"tags": ["tech"]
			},
			{
				"id": "http://bsweger.micro.blog/2025/01/23/more-machines-more-python-setup.html",
				"title": "More machines, more Python setup problems",
				"content_html": "<p>After working at a large tech company for nearly six years, I was unprepared for how spoiled I&rsquo;d gotten when working on teams with uniform technology. Teams where everyone is admin on their corporate-issued laptops all running the same OS. Teams where 85% of software engineers use the same IDE.</p>\n<p>Within that kind of environment, if you write instructions for setting up and contributing to a Python project, those instructions will almost certainly work on everyone else&rsquo;s machine.</p>\n<p>But when no two teammates—let alone potential contributors to our open source software—have the same setup, all bets are off:</p>\n<ul>\n<li>IT restrictions block the thing</li>\n<li>The Makefile doesn&rsquo;t run on Windows</li>\n<li>Conda edited .bashrc and stuck its base Python environment at the beginning of $PATH</li>\n<li>IDE can&rsquo;t find the virtual environment</li>\n<li>Anti-virus blocks the other thing</li>\n<li>Docker malarkey</li>\n</ul>\n<p>Hence, all the <a href=\"https://beckysweger.com/2025/01/09/im-gonna-write-about-uv.html\">uv</a> <a href=\"https://beckysweger.com/2025/01/14/python-uv-contributing-is-caring.html\">posts</a>. Sure, the speed is nice, and <a href=\"https://beckysweger.com/2025/01/06/change-your-life-with-uv.html\">using <code>uv run</code> to share scripts is A++</a>. But it&rsquo;s also the only all-in-one Python installer, venv, and dependency management tool we&rsquo;ve tried that actually does what we need and so far runs as expected on everyone&rsquo;s machine.</p>\n",
				"content_text": "After working at a large tech company for nearly six years, I was unprepared for how spoiled I'd gotten when working on teams with uniform technology. Teams where everyone is admin on their corporate-issued laptops all running the same OS. Teams where 85% of software engineers use the same IDE.\r\n\r\nWithin that kind of environment, if you write instructions for setting up and contributing to a Python project, those instructions will almost certainly work on everyone else's machine.\r\n\r\nBut when no two teammates—let alone potential contributors to our open source software—have the same setup, all bets are off:\r\n\r\n- IT restrictions block the thing\r\n- The Makefile doesn't run on Windows\r\n- Conda edited .bashrc and stuck its base Python environment at the beginning of $PATH\r\n- IDE can't find the virtual environment\r\n- Anti-virus blocks the other thing\r\n- Docker malarkey\r\n\r\nHence, all the [uv](https://beckysweger.com/2025/01/09/im-gonna-write-about-uv.html) [posts](https://beckysweger.com/2025/01/14/python-uv-contributing-is-caring.html). Sure, the speed is nice, and [using `uv run` to share scripts is A++](https://beckysweger.com/2025/01/06/change-your-life-with-uv.html). But it's also the only all-in-one Python installer, venv, and dependency management tool we've tried that actually does what we need and so far runs as expected on everyone's machine.\r\n\r\n",
				"date_published": "2025-01-23T21:30:31-05:00",
				"url": "https://beckysweger.com/2025/01/23/more-machines-more-python-setup.html",
				"tags": ["tech","python"]
			},
			{
				"id": "http://bsweger.micro.blog/2025/01/16/living-that-tokenfree-life.html",
				"title": "Living that token-free life",
				"content_html": "<p>Finally published something to PyPi (Python&rsquo;s packaging index) after more than a decade of writing Python. It&rsquo;s not exactly new news, but the <a href=\"https://docs.pypi.org/trusted-publishers/\">trusted publishing feature</a> is A++  and straightforward to set up if you use GitHub actions to write to PyPI</p>\n<p>When they first hear the lack of tokens, people can be pretty skeptical about OIDC + GitHub Actions + PyPy/AWS/whatever.  We&rsquo;ve been conditioned to equate long, weird-looking strings with security, so the idea of <em>not</em> having a long, weird-looking string seems wrong somehow.</p>\n<p>I&rsquo;ve struggled to explain clearly how the pieces fit together and was happy to stumble on this 2023 explainer from Trail of Bits, who worked with the Python Packaging Authority (PyPA) to implement trusted publishers. Bookmarked!</p>\n<p><a href=\"https://blog.trailofbits.com/2023/05/23/trusted-publishing-a-new-benchmark-for-packaging-security/\">blog.trailofbits.com/2023/05/2&hellip;</a></p>\n",
				"content_text": "Finally published something to PyPi (Python's packaging index) after more than a decade of writing Python. It's not exactly new news, but the [trusted publishing feature](https://docs.pypi.org/trusted-publishers/) is A++  and straightforward to set up if you use GitHub actions to write to PyPI\r\n\r\nWhen they first hear the lack of tokens, people can be pretty skeptical about OIDC + GitHub Actions + PyPy/AWS/whatever.  We've been conditioned to equate long, weird-looking strings with security, so the idea of _not_ having a long, weird-looking string seems wrong somehow.\r\n\r\nI've struggled to explain clearly how the pieces fit together and was happy to stumble on this 2023 explainer from Trail of Bits, who worked with the Python Packaging Authority (PyPA) to implement trusted publishers. Bookmarked!\r\n\r\n[blog.trailofbits.com/2023/05/2...](https://blog.trailofbits.com/2023/05/23/trusted-publishing-a-new-benchmark-for-packaging-security/)\r\n\r\n",
				"date_published": "2025-01-16T20:23:16-05:00",
				"url": "https://beckysweger.com/2025/01/16/living-that-tokenfree-life.html",
				"tags": ["tech","python"]
			},
			{
				"id": "http://bsweger.micro.blog/2025/01/14/python-uv-contributing-is-caring.html",
				"title": "Python uv: slaying the project setup yaks",
				"content_html": "<p>Life with <code>uv run</code> is going well. The <a href=\"https://beckysweger.com/2025/01/06/change-your-life-with-uv.html\">aforementioned smart, busy colleagues who mostly program in R</a> have <code>uv</code> installed on their machines and the shared Python scripts are flowing.</p>\n<p>You&rsquo;re now ready for Phase 2 of &ldquo;no more Futzing Around™️ with Python.&rdquo;</p>\n<p>One day, a colleague wants to update an internally-developed Python package. That person may not write a lot of Python, but they can certainly fix a straightforward bug or typo. So they refer to <code>CONTRIBUTING.md</code> and find the following instructions for creating a dev environment:</p>\n<ol>\n<li>Clone the repo.</li>\n<li>Look at <code>.python-version</code> to find out which version of Python we&rsquo;re using for development.</li>\n<li>Install pyenv and use pyenv to install the above version of Python.</li>\n<li>Create a virtual environment. It’s tempting to skip this step, but please don’t. You can use python, pyenv-virtualenv, poetry, conda, pdm, hatch, pipenv, rye, or uv to create a virtual environment. <code>CONTRIBUTING.md</code> recommends whatever tool its author likes.</li>\n<li>Activate the virtual environment.</li>\n<li>Install the package dev dependencies: <code>pip install -r requirements-dev.txt</code></li>\n<li>Install the package as an editable module: <code>pip install -e .</code></li>\n<li>Before making your change run the tests to ensure all is well: <code>pytest</code></li>\n</ol>\n<p>Now that everyone on the team has <code>uv</code> installed, you can simplify <code>CONTRIBUTING.md</code> to something like this:</p>\n<ol>\n<li>Clone the repo.</li>\n<li>Create a virtual environment: <code>uv venv --seed</code>¹</li>\n<li>Install the package dev dependencies: <code>uv pip install -r requirements-dev.txt</code></li>\n<li>Install the package as an editable module: <code>uv pip install -e .</code></li>\n<li>Before making your change run the tests to ensure all is well: <code>uv run pytest</code></li>\n</ol>\n<p>I like this approach for two reasons:</p>\n<ol>\n<li>It removes barriers to entry for potential collaborators.</li>\n<li>Yet it doesn&rsquo;t require existing contributors to change the way they work. People are free to handle their own Python installs, virtual environments, and dependencies as they see fit (as long as they generate annotated requirements.txt files when updating dependencies).²</li>\n</ol>\n<p>¹ <a href=\"https://beckysweger.com/2025/01/14/seeding-virtual-environments-with-pip.html\"><code>--seed</code> tells <code>uv</code> to include seed packages like <code>pip</code> and <code>setuptools</code> in the virtual environment it creates</a>. It&rsquo;s helpful for people who would rather activate the environment instead of prefixing every command with <code>uv run</code> or <code>uv pip</code>.</p>\n<p>² Add <code>uv.lock</code> to <code>.gitignore</code> to remove any confusion on this point.</p>\n",
				"content_text": "Life with `uv run` is going well. The [aforementioned smart, busy colleagues who mostly program in R](https://beckysweger.com/2025/01/06/change-your-life-with-uv.html) have `uv` installed on their machines and the shared Python scripts are flowing.\n\nYou're now ready for Phase 2 of \"no more Futzing Around™️ with Python.\"\n\nOne day, a colleague wants to update an internally-developed Python package. That person may not write a lot of Python, but they can certainly fix a straightforward bug or typo. So they refer to `CONTRIBUTING.md` and find the following instructions for creating a dev environment:\n\n1. Clone the repo.\n2. Look at `.python-version` to find out which version of Python we're using for development.\n3. Install pyenv and use pyenv to install the above version of Python.\n4. Create a virtual environment. It’s tempting to skip this step, but please don’t. You can use python, pyenv-virtualenv, poetry, conda, pdm, hatch, pipenv, rye, or uv to create a virtual environment. `CONTRIBUTING.md` recommends whatever tool its author likes.\n5. Activate the virtual environment.\n6. Install the package dev dependencies: `pip install -r requirements-dev.txt`\n7. Install the package as an editable module: `pip install -e .`\n8. Before making your change run the tests to ensure all is well: `pytest`\n\nNow that everyone on the team has `uv` installed, you can simplify `CONTRIBUTING.md` to something like this:\n\n1. Clone the repo.\n2. Create a virtual environment: `uv venv --seed`¹\n3. Install the package dev dependencies: `uv pip install -r requirements-dev.txt`\n4. Install the package as an editable module: `uv pip install -e .`\n5. Before making your change run the tests to ensure all is well: `uv run pytest`\n\nI like this approach for two reasons:\n\n1. It removes barriers to entry for potential collaborators.\n2. Yet it doesn't require existing contributors to change the way they work. People are free to handle their own Python installs, virtual environments, and dependencies as they see fit (as long as they generate annotated requirements.txt files when updating dependencies).²\n\n¹ [`--seed` tells `uv` to include seed packages like `pip` and `setuptools` in the virtual environment it creates](https://beckysweger.com/2025/01/14/seeding-virtual-environments-with-pip.html). It's helpful for people who would rather activate the environment instead of prefixing every command with `uv run` or `uv pip`.\n\n² Add `uv.lock` to `.gitignore` to remove any confusion on this point.\n\n",
				"date_published": "2025-01-14T10:26:00-05:00",
				"url": "https://beckysweger.com/2025/01/14/python-uv-contributing-is-caring.html",
				"tags": ["tech","python","uv"]
			},
			{
				"id": "http://bsweger.micro.blog/2025/01/14/seeding-virtual-environments-with-pip.html",
				"title": "Seeding uv virtual environments with pip",
				"content_html": "<p>It&rsquo;s great that a <a href=\"https://docs.astral.sh/uv/reference/cli/#uv-venv\">uv-created Python virtual environment</a> lives where you&rsquo;d expect it to be: in a folder called <code>.venv</code>. You can still use your muscle memory <code>source .venv/bin/activate</code> incantation to activate it.</p>\n<p>But other muscle memory commands don&rsquo;t work as well, especially those related to <code>pip</code>. By default,  <code>pip</code> isn&rsquo;t installed into uv virtual environments. So you have to do things like <code>uv pip list</code> instead of <code>pip list</code>.</p>\n<p>The uv <code>--seed</code> option fixes that by installing <code>pip</code> and other seed packages into the new environment: <code>uv venv --seed</code>.</p>\n<p>I ended up aliasing <code>uv venv</code> to <code>uv venv --seed</code> with the following function in ye old <code>.zshrc</code>:¹</p>\n<pre tabindex=\"0\"><code class=\"language-script\" data-lang=\"script\">uv() {\n  if [ &quot;$1&quot; = &quot;venv&quot; ]; then\n    shift\n    command uv venv --shell &quot;$@&quot;\n  else\n    command uv &quot;$@&quot;\n  fi\n}\n</code></pre><p>¹ Here&rsquo;s a scenario where GitHub Copilot is helpful.</p>\n",
				"content_text": "It's great that a [uv-created Python virtual environment](https://docs.astral.sh/uv/reference/cli/#uv-venv) lives where you'd expect it to be: in a folder called `.venv`. You can still use your muscle memory `source .venv/bin/activate` incantation to activate it.\n\nBut other muscle memory commands don't work as well, especially those related to `pip`. By default,  `pip` isn't installed into uv virtual environments. So you have to do things like `uv pip list` instead of `pip list`.\n\nThe uv `--seed` option fixes that by installing `pip` and other seed packages into the new environment: `uv venv --seed`.\n\nI ended up aliasing `uv venv` to `uv venv --seed` with the following function in ye old `.zshrc`:¹\n\n```script\nuv() {\n  if [ \"$1\" = \"venv\" ]; then\n    shift\n    command uv venv --shell \"$@\"\n  else\n    command uv \"$@\"\n  fi\n}\n```\n¹ Here's a scenario where GitHub Copilot is helpful.\n\n\n",
				"date_published": "2025-01-14T09:03:13-05:00",
				"url": "https://beckysweger.com/2025/01/14/seeding-virtual-environments-with-pip.html",
				"tags": ["til","python","uv"]
			},
			{
				"id": "http://bsweger.micro.blog/2025/01/06/change-your-life-with-uv.html",
				"title": "Python + uv run: sharing is caring",
				"content_html": "<p>Imagine that your colleagues—very smart, busy people who mostly program in R—need a dataset that&rsquo;s difficult to create. And they want the ability to recreate the dataset as often as necessary. The freedom to tweak the code and experiment with the inputs.</p>\n<h2 id=\"without-uv\">Without uv</h2>\n<p>Good news! You have a script that does exactly what they need. It&rsquo;s written in Python instead of R, but anyone can run it by following these simple steps:</p>\n<ol>\n<li>Install Python. Python is already on your laptop, but don&rsquo;t use that one. Install a different Python. Actually, just install pyenv and then use pyenv to install Python.</li>\n<li>Create a virtual environment. It&rsquo;s tempting to skip this step, but please don&rsquo;t. You can use python, pyenv-virtualenv, poetry, conda, pdm, hatch, pipenv, rye, or uv to create a virtual environment. I will make a recommendation. Next month I will make a different recommendation.</li>\n<li>Activate your virtual environment.</li>\n<li>The script uses polars, biopython, and zstandard, so use pip to install those dependencies. Don&rsquo;t install polars 1.17.0, everything will break.</li>\n<li>Run the script: <code>python very-useful-script.py</code></li>\n</ol>\n<h2 id=\"with-uv\">With uv</h2>\n<p>Good news! You have a script that does exactly what they need. It&rsquo;s written in Python instead of R, but anyone can run it by following these simple steps:</p>\n<ol>\n<li>Install <a href=\"https://docs.astral.sh/uv/\">uv</a></li>\n<li>Use <a href=\"https://docs.astral.sh/uv/guides/scripts/\"><code>uv run</code></a> to execute the script: <code>uv run very-useful-script.py</code></li>\n</ol>\n",
				"content_text": "Imagine that your colleagues—very smart, busy people who mostly program in R—need a dataset that's difficult to create. And they want the ability to recreate the dataset as often as necessary. The freedom to tweak the code and experiment with the inputs.\n\n## Without uv\n\nGood news! You have a script that does exactly what they need. It's written in Python instead of R, but anyone can run it by following these simple steps:\n\n1. Install Python. Python is already on your laptop, but don't use that one. Install a different Python. Actually, just install pyenv and then use pyenv to install Python.\n2. Create a virtual environment. It's tempting to skip this step, but please don't. You can use python, pyenv-virtualenv, poetry, conda, pdm, hatch, pipenv, rye, or uv to create a virtual environment. I will make a recommendation. Next month I will make a different recommendation.\n3. Activate your virtual environment.\n4. The script uses polars, biopython, and zstandard, so use pip to install those dependencies. Don't install polars 1.17.0, everything will break.\n5. Run the script: `python very-useful-script.py`\n\n\n## With uv\n\nGood news! You have a script that does exactly what they need. It's written in Python instead of R, but anyone can run it by following these simple steps:\n\n1. Install [uv](https://docs.astral.sh/uv/)\n2. Use [`uv run`](https://docs.astral.sh/uv/guides/scripts/) to execute the script: `uv run very-useful-script.py`\n\n",
				"date_published": "2025-01-06T09:55:00-05:00",
				"url": "https://beckysweger.com/2025/01/06/change-your-life-with-uv.html",
				"tags": ["stories","tech","python","uv"]
			}
	]
}
